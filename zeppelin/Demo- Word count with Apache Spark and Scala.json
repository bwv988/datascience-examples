{"paragraphs":[{"text":"%md\n\n# Demo: Word count with Apache Spark and Scala\n\nThis demo shows how to use Spark to run a simple word count on a text file.\n\nFirst, let's create a test file in the working directory and put in some text.\n","dateUpdated":"2016-11-14T19:32:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1477475467613_468376035","id":"20161024-110155_1177149201","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Demo: Word count with Apache Spark and Scala</h1>\n<p>This demo shows how to use Spark to run a simple word count on a text file.</p>\n<p>First, let's create a test file in the working directory and put in some text.</p>\n"},"dateCreated":"2016-10-26T09:51:07+0000","dateStarted":"2016-11-14T19:32:41+0000","dateFinished":"2016-11-14T19:32:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10188","focus":true},{"text":"%sh\n\n# Download an input file.\n\nrm -rf /workdir/wordcount\nmkdir -p /workdir/wordcount\ncd /workdir/wordcount\nwget http://norvig.com/ngrams/smaller.txt\n\nls -ls /workdir/wordcount\n","dateUpdated":"2016-11-14T19:32:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1477475467614_469530281","id":"20161026-042322_562630230","result":{"code":"SUCCESS","type":"TEXT","msg":"converted 'http://norvig.com/ngrams/smaller.txt' (ANSI_X3.4-1968) -> 'http://norvig.com/ngrams/smaller.txt' (UTF-8)\n--2016-11-14 19:32:41--  http://norvig.com/ngrams/smaller.txt\nResolving norvig.com (norvig.com)... 192.220.74.115\nConnecting to norvig.com (norvig.com)|192.220.74.115|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1000575 (977K) [text/plain]\nSaving to: 'smaller.txt'\n\n     0K .......... .......... .......... .......... ..........  5% 74.6K 12s\n    50K .......... .......... .......... .......... .......... 10%  150K 9s\n   100K .......... .......... .......... .......... .......... 15%  296K 6s\n   150K .......... .......... .......... .......... .......... 20%  150K 6s\n   200K .......... .......... .......... .......... .......... 25%  296K 5s\n   250K .......... .......... .......... .......... .......... 30%  150K 5s\n   300K .......... .......... .......... .......... .......... 35%  150K 4s\n   350K .......... .......... .......... .......... .......... 40%  292K 4s\n   400K .......... .......... .......... .......... .......... 46%  150K 3s\n   450K .......... .......... .......... .......... .......... 51%  296K 3s\n   500K .......... .......... .......... .......... .......... 56%  150K 3s\n   550K .......... .......... .......... .......... .......... 61%  296K 2s\n   600K .......... .......... .......... .......... .......... 66%  150K 2s\n   650K .......... .......... .......... .......... .......... 71%  295K 2s\n   700K .......... .......... .......... .......... .......... 76%  149K 1s\n   750K .......... .......... .......... .......... .......... 81%  151K 1s\n   800K .......... .......... .......... .......... .......... 86%  293K 1s\n   850K .......... .......... .......... .......... .......... 92%  150K 0s\n   900K .......... .......... .......... .......... .......... 97%  295K 0s\n   950K .......... .......... .......                         100%  163K=5.5s\n\n2016-11-14 19:32:55 (177 KB/s) - 'smaller.txt' saved [1000575/1000575]\n\ntotal 980\n980 -rw-r--r-- 1 root root 1000575 Jan 24  2015 smaller.txt\n"},"dateCreated":"2016-10-26T09:51:07+0000","dateStarted":"2016-11-14T19:32:41+0000","dateFinished":"2016-11-14T19:32:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10189","focus":true},{"text":"// Simple wordcount in Scala / Spark.\n\nimport sqlContext.implicits._\n\nval inFilePath = \"file:///workdir/wordcount/smaller.txt\"\nval outFilePath = \"file:///workdir/wordcount/results\"\n\nval linesDF = sc.textFile(inFilePath).toDF(\"line\")\nval wordsDF = linesDF.explode(\"line\", \"word\")((line: String) => line.split(\" \"))\nval wordCountDF = wordsDF.groupBy(\"word\").count()\n\n// Show some results.\nwordCountDF.show()\n\n// Register in-memory table.\nwordCountDF.createOrReplaceTempView(\"wordCounts\")\n","dateUpdated":"2016-11-14T19:33:36+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1477475467614_469530281","id":"20160905-210214_451902869","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport sqlContext.implicits._\n\ninFilePath: String = file:///workdir/wordcount/smaller.txt\n\noutFilePath: String = file:///workdir/wordcount/results\n\nlinesDF: org.apache.spark.sql.DataFrame = [line: string]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n\nwordsDF: org.apache.spark.sql.DataFrame = [line: string, word: string]\n\nwordCountDF: org.apache.spark.sql.DataFrame = [word: string, count: bigint]\n+---------+-----+\n|     word|count|\n+---------+-----+\n|    cold,|    5|\n|    those|  108|\n|     some|  271|\n|      few|  113|\n|       By|   45|\n|    'Eg.'|    1|\n|      Sit|    2|\n|    still|   92|\n|   back.\"|    4|\n|     me?\"|    5|\n|     hope|   30|\n|occupant.|    2|\n|   lady's|    7|\n| everyday|    1|\n|connected|   10|\n|   youth,|    5|\n|     'And|   11|\n|    pens,|    1|\n|  WILSON\"|    1|\n|    turn,|    7|\n+---------+-----+\nonly showing top 20 rows\n\n"},"dateCreated":"2016-10-26T09:51:07+0000","dateStarted":"2016-11-14T19:33:36+0000","dateFinished":"2016-11-14T19:33:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10190","focus":true},{"text":"%md\n\nNow let's look at the top 5 most frequently used words:","dateUpdated":"2016-11-14T19:32:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1477475467614_469530281","id":"20161026-045211_637056511","result":{"code":"SUCCESS","type":"HTML","msg":"<p>Now let's look at the top 5 most frequently used words:</p>\n"},"dateCreated":"2016-10-26T09:51:07+0000","dateStarted":"2016-11-14T19:32:41+0000","dateFinished":"2016-11-14T19:32:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10191","focus":true},{"text":"%sql \nselect * from wordCounts order by count desc limit 5","dateUpdated":"2016-11-14T19:33:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"word","index":0,"aggr":"sum"}],"values":[{"name":"count","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"word","index":0,"aggr":"sum"},"yAxis":{"name":"count","index":1,"aggr":"sum"}}},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1477475467614_469530281","id":"20160922-113440_706679649","result":{"code":"SUCCESS","type":"TABLE","msg":"word\tcount\nthe\t11089\n\t9373\nof\t6216\nand\t4939\nto\t4462\n","comment":"","msgTable":[[{"key":"count","value":"the"},{"key":"count","value":"11089"}],[{"value":""},{"value":"9373"}],[{"value":"of"},{"value":"6216"}],[{"value":"and"},{"value":"4939"}],[{"value":"to"},{"value":"4462"}]],"columnNames":[{"name":"word","index":0,"aggr":"sum"},{"name":"count","index":1,"aggr":"sum"}],"rows":[["the","11089"],["","9373"],["of","6216"],["and","4939"],["to","4462"]]},"dateCreated":"2016-10-26T09:51:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10192","dateFinished":"2016-11-14T19:33:42+0000","dateStarted":"2016-11-14T19:33:41+0000","focus":true},{"text":"","dateUpdated":"2016-11-14T19:32:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1477475467614_469530281","id":"20161026-045235_1408516944","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-10-26T09:51:07+0000","dateStarted":"2016-11-14T19:32:45+0000","dateFinished":"2016-11-14T19:32:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10193"}],"name":"Demo: Word count with Apache Spark and Scala","id":"2BYEGP162","angularObjects":{"2C33SEXWG:shared_process":[],"2C3QR63TM:shared_process":[],"2C23GA16A:shared_process":[],"2C1N5APBF:shared_process":[],"2C1FEY6YD:shared_process":[],"2C2J74PYC:shared_process":[],"2BZU7Z8ZB:shared_process":[],"2C236Q7H4:shared_process":[],"2C25K3WSV:shared_process":[],"2C3EXU5NG:shared_process":[],"2C2YDCEMZ:shared_process":[],"2C3Z2QP3Y:shared_process":[],"2C4EED9K4:shared_process":[],"2BZN5DSC4:shared_process":[],"2C36M7VK8:shared_process":[],"2C3K582G7:shared_process":[],"2BZSAUEGS:shared_process":[],"2C2YR1SN1:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}